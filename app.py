import json
import asyncio
import logging
from typing import Dict,List,Any,Optional
from workers import ImageSegmentationWorker, PointCloudMappingWorker, RigidMotionWorker
# from llm import QwenLLMClient
from Planner import Planner
from dataclasses import dataclass
from enum import Enum
from abc import ABC,abstractmethod
from workers import *
from TypeEnums import *
import openai
logging.basicConfig(level=logging.INFO,format='%(asctime)s-%(levelname)s-%(message)s')
logger=logging.getLogger(__name__)

class PointCloudMappingWorker(BaseWorker):
    def __init__(self):
        super(PointCloudMappingWorker, self).__init__("worker2","pointcloud_segmentation")
    async def execute(self,task)->WorkerResult:
        logger.info(f"Worker2æ‰§è¡Œ3Mæ˜ å°„ä»»åŠ¡:{task.description}")
        await asyncio.sleep(2)
        mock_data={
            "mapped_pointcloud":"mapped_points.pcd",
            "pointcloud_coordinates":[[100,200,300],[100,200,300]],
            "target_points":[[x,y,z] for x,y,z in[(1,2,3),(4,5,6)]],
            "confidence":0.92
        }
        return WorkerResult(success=True,data=mock_data)

class ImageSegmentationWorker(BaseWorker):
    def __init__(self):
        super(ImageSegmentationWorker, self).__init__("worker1","image_segmentation")
        self.supported_methods={
            "lang_sam":self._execute_lang_sam,
            "dino":self._execute_dino,
        }
        self.min_quality_threshold=0.7
        self.max_retry_attempts=3
    async def execute(self,task:Task) ->WorkerResult:
        try:
            logger.info(f"Worker1å¼€å§‹æ‰§è¡Œ:{task.description}")
            instruction=task.input_data.get("instruction","")
            target_subject=task.input_data.get("target_subject",[])
            target_parts = task.input_data.get("target_parts", [])
            segmentation_method = task.input_data.get("segmentation_method", "lang_sam")
            precision_level=task.input_data.get("precision_level","high")
            image_path=task.input_data.get("image_path","")
            retry_count=task.input_data.get("retry_count",0)
            previous_issues=task.input_data.get("previous_issues",[])
            logger.info(f"åˆ†å‰²æ–¹æ³•: {segmentation_method},é‡è¯•æ¬¡æ•°:{retry_count}")
            logger.info(f"ç›®æ ‡å¯¹è±¡: {target_subject}, ç›®æ ‡éƒ¨ä½: {target_parts}")
            logger.info(f"ç²¾åº¦è¦æ±‚: {precision_level}")
            if retry_count>0:
                segmentation_method,previous_level,instruction=self._adjust_parameters_for_retry\
                    (previous_issues, segmentation_method, precision_level, instruction)
                logger.info(f"é‡è¯•è°ƒæ•´å - æ–¹æ³•: {segmentation_method}, ç²¾åº¦: {precision_level}")
            #æ„å»ºæ–‡æœ¬æç¤º
            text_prompt=self._build_text_prompt(target_subject,target_parts,instruction)
            logger.info(f"æ„å»ºæ–‡æœ¬æç¤º:{text_prompt}")
            segmentation_func=self.supported_methods.get(segmentation_method)
            result=await segmentation_func(image_path,text_prompt,precision_level)
            processed_result=self._post_process_segmentation(result,target_parts)
            # è¯„ä¼°åˆ†å‰²è´¨é‡
            quality_assessment = self._assess_segmentation_quality(processed_result)
            logger.info(f"åˆ†å‰²è´¨é‡è¯„ä¼°: {quality_assessment}")

            # å°†è´¨é‡è¯„ä¼°ç»“æœæ·»åŠ åˆ°å¤„ç†ç»“æœä¸­
            processed_result["quality_assessment"] = quality_assessment
            processed_result["retry_count"] = retry_count
            if self._should_retry(quality_assessment,retry_count):
                return self._create_retry_result(processed_result,quality_assessment,task)
            else:
                success=quality_assessment["overall_score"]>=self.min_quality_threshold
                return WorkerResult(success=True,data=processed_result,
                feedback_to_planner=self._generate_planner_feedback(quality_assessment, success,retry_count))
        except Exception as e:
            logger.info(f"å›¾åƒåˆ†å‰²å¤±è´¥{e}")
            return WorkerResult(success=False,data=[],feedback_to_planner={
                "action":"task_failed",
                "reason":f"æ‰§è¡Œå¼‚å¸¸:{str(e)}",
                "recommendations":["æ£€æŸ¥è¾“å…¥å‚æ•°","éªŒè¯å›¾åƒè·¯å¾„","ç¡®è®¤åˆ†å‰²æ–¹æ³•å¯ç”¨æ€§"]
            })
    def _should_retry(self,quality_assessment:dict,retry_count:int)->bool:
        quality_below_threshold=quality_assessment["overall_score"]<self.min_quality_threshold
        not_max_retries=retry_count<self.max_retry_attempts
        has_actionable_issues=bool(quality_assessment.get("recommendations"))
        return quality_below_threshold and not_max_retries and has_actionable_issues
    def _create_retry_result(self,processed_result:dict,quality_assessment:dict,original_task:Task)->WorkerResult:
        retry_feedback={
            "action":"retry_required",
            "reason":f"åˆ†å‰²è´¨é‡ä¸è¾¾æ ‡(å¾—åˆ†: {quality_assessment['overall_score']:.2f}, é˜ˆå€¼: {self.min_quality_threshold})",
            "current_issues":quality_assessment["issues"],
            "recommendations":quality_assessment["recommendations"],
            "suggested_adjustments":self._get_parameter_adjustments(quality_assessment["issues"]),
            "retry_task_data":self._prepare_retry_task_data(original_task,quality_assessment)
        }
        return WorkerResult(
            success=False,
            data=processed_result,
            feedback_to_planner=retry_feedback
        )

    def _prepare_retry_task_data(self, original_task: Task, quality_assessment: dict) -> dict:
        """å‡†å¤‡é‡è¯•ä»»åŠ¡æ•°æ®"""
        retry_data = original_task.input_data.copy()
        retry_data["retry_count"] = retry_data.get("retry_count", 0) + 1
        retry_data["previous_issues"] = quality_assessment["issues"]
        retry_data["previous_score"] = quality_assessment["overall_score"]

        return retry_data
    def _adjust_parameters_for_retry(self, previous_issues: list, current_method: str,
                                     current_precision: str, current_instruction: str) -> tuple:
        """æ ¹æ®ä¹‹å‰çš„é—®é¢˜è°ƒæ•´å‚æ•°"""
        new_method = current_method
        new_precision = current_precision
        new_instruction = current_instruction

        # æ ¹æ®å…·ä½“é—®é¢˜è°ƒæ•´å‚æ•°
        if "Low confidence scores" in previous_issues:
            # å°è¯•åˆ‡æ¢åˆ†å‰²æ–¹æ³•
            if current_method == "lang_sam":
                new_method = "dino"
            else:
                new_method = "lang_sam"
            logger.info(f"ç”±äºç½®ä¿¡åº¦ä½ï¼Œåˆ‡æ¢åˆ†å‰²æ–¹æ³•ä» {current_method} åˆ° {new_method}")

        if "Some regions too small" in previous_issues:
            # é™ä½ç²¾åº¦è¦æ±‚ä»¥è·å¾—æ›´å¤§çš„åŒºåŸŸ
            precision_map = {"high": "medium", "medium": "low", "low": "low"}
            new_precision = precision_map.get(current_precision, "medium")
            logger.info(f"ç”±äºåŒºåŸŸè¿‡å°ï¼Œè°ƒæ•´ç²¾åº¦ä» {current_precision} åˆ° {new_precision}")

        if "No target parts detected" in previous_issues:
            # å¢å¼ºæ–‡æœ¬æç¤º
            new_instruction = f"{current_instruction} è¯·æ›´ç²¾ç¡®åœ°å®šä½ç›®æ ‡åŒºåŸŸ"
            logger.info("ç”±äºæœªæ£€æµ‹åˆ°ç›®æ ‡ï¼Œå¢å¼ºæ–‡æœ¬æç¤º")

        return new_method, new_precision, new_instruction
    def _build_text_prompt(self,subject:str,target_parts:list,instruction:str)->str:
        if not target_parts:
            return f"segment {subject} in the image"
        parts_str=" and ".join(target_parts)
        if "æŒ¥èˆ" in instuction or "wave" in instruction.lower():
            prompt=f"segment the {parts_str} of {subject} that will be used for waving motion"
        elif "è½¬åŠ¨" in instruction or "rotate" in instruction.lower():
            prompt=f"segment the {parts_str} of {subject} that will rotate"
        elif "æ‘†åŠ¨" in instruction or "swing" in instruction.lower():
            prompt=f"segment the {parts_str} of {subject} that will swing"
        else:
            prompt =f"segment the {parts_str} of {subject}"
        prompt+=",focus on precise boundaries"
        return prompt

    async def _execute_lang_sam(self, image_path: str, text_prompt: str, precision_level: str) -> dict:
        """æ‰§è¡ŒLang-SAMåˆ†å‰²"""
        logger.info("ä½¿ç”¨Lang-SAMè¿›è¡Œæ–‡æœ¬æŒ‡å¼•åˆ†å‰²")

        # æ¨¡æ‹ŸLang-SAMè°ƒç”¨è¿‡ç¨‹
        await asyncio.sleep(2)  # æ¨¡æ‹Ÿåˆ†å‰²æ—¶é—´

        # TODO: å®é™…è°ƒç”¨Lang-SAM
        """
        å®é™…å®ç°åº”è¯¥æ˜¯ï¼š

        import torch
        from lang_sam import LangSAM

        # åˆå§‹åŒ–Lang-SAMæ¨¡å‹
        model = LangSAM()

        # åŠ è½½å›¾åƒ
        image = Image.open(image_path)

        # æ‰§è¡Œåˆ†å‰²
        masks, boxes, phrases, logits = model.predict(image, text_prompt)

        # å¤„ç†ç»“æœ...
        """

        # æ¨¡æ‹Ÿè¿”å›ç»“æœ
        mock_result = {
            "method": "lang_sam",
            "masks": self._generate_mock_masks(),
            "bounding_boxes": [[50, 50, 150, 150], [200, 100, 300, 200]],
            "confidence_scores": [0.92, 0.87],
            "phrases": ["left hand", "right hand"],
            "logits": [4.2, 3.8]
        }

        return mock_result

    async def _execute_dino(self, image_path: str, text_prompt: str, precision_level: str) -> dict:
        """æ‰§è¡ŒDINOåˆ†å‰²"""
        logger.info("ä½¿ç”¨DINOè¿›è¡Œç‰©ä½“åˆ†å‰²")

        await asyncio.sleep(1.5)  # æ¨¡æ‹Ÿåˆ†å‰²æ—¶é—´

        # TODO: å®é™…è°ƒç”¨DINO
        """
        å®é™…å®ç°åº”è¯¥æ˜¯ï¼š

        from transformers import AutoImageProcessor, AutoModel
        import torch

        # åŠ è½½DINOæ¨¡å‹
        processor = AutoImageProcessor.from_pretrained('facebook/dino-vitb16')
        model = AutoModel.from_pretrained('facebook/dino-vitb16')

        # å¤„ç†å›¾åƒ
        image = Image.open(image_path)
        inputs = processor(images=image, return_tensors="pt")

        # è·å–ç‰¹å¾
        with torch.no_grad():
            outputs = model(**inputs)

        # åŸºäºç‰¹å¾è¿›è¡Œåˆ†å‰²...
        """

        # æ¨¡æ‹Ÿè¿”å›ç»“æœ
        mock_result = {
            "method": "dino",
            "masks": self._generate_mock_masks(),
            "bounding_boxes": [[60, 60, 160, 160], [210, 110, 310, 210]],
            "confidence_scores": [0.89, 0.84],
            "phrases": ["detected region 1", "detected region 2"],
            "features": "mock_features"
        }

        return mock_result

    def _generate_mock_masks(self) -> list:
        """ç”Ÿæˆæ¨¡æ‹Ÿçš„åˆ†å‰²æ©ç æ•°æ®"""
        # æ¨¡æ‹Ÿä¸¤ä¸ªåˆ†å‰²åŒºåŸŸçš„åƒç´ åæ ‡
        mask1_pixels = []
        mask2_pixels = []

        # æ¨¡æ‹Ÿç¬¬ä¸€ä¸ªåŒºåŸŸ (å·¦æ‰‹åŒºåŸŸ: 50x50 åˆ° 150x150)
        for y in range(50, 151):
            for x in range(50, 151):
                if (x - 100) ** 2 + (y - 100) ** 2 <= 2500:  # åœ†å½¢åŒºåŸŸ
                    mask1_pixels.append([x, y])

        # æ¨¡æ‹Ÿç¬¬äºŒä¸ªåŒºåŸŸ (å³æ‰‹åŒºåŸŸ: 200x100 åˆ° 300x200)
        for y in range(100, 201):
            for x in range(200, 301):
                if (x - 250) ** 2 + (y - 150) ** 2 <= 2500:  # åœ†å½¢åŒºåŸŸ
                    mask2_pixels.append([x, y])

        return [
            {
                "region_id": 1,
                "pixel_coordinates": mask1_pixels,
                "pixel_count": len(mask1_pixels),
                "center": [100, 100],
                "area": len(mask1_pixels)
            },
            {
                "region_id": 2,
                "pixel_coordinates": mask2_pixels,
                "pixel_count": len(mask2_pixels),
                "center": [250, 150],
                "area": len(mask2_pixels)
            }
        ]

    def _post_process_segmentation(self, raw_result: dict, target_parts: list) -> dict:
        """åå¤„ç†åˆ†å‰²ç»“æœ"""
        processed_result = {
            "segmentation_method": raw_result.get("method", "unknown"),
            "segmented_regions": [],
            "total_regions": len(raw_result.get("masks", [])),
            "success": True
        }

        masks = raw_result.get("masks", [])
        boxes = raw_result.get("bounding_boxes", [])
        confidences = raw_result.get("confidence_scores", [])
        phrases = raw_result.get("phrases", [])

        # å¤„ç†æ¯ä¸ªåˆ†å‰²åŒºåŸŸ
        for i, mask in enumerate(masks):
            region_info = {
                "region_id": i + 1,
                "target_part": phrases[i] if i < len(phrases) else f"region_{i + 1}",
                "pixel_coordinates": mask["pixel_coordinates"],
                "pixel_count": mask["pixel_count"],
                "bounding_box": {
                    "x1": boxes[i][0] if i < len(boxes) else 0,
                    "y1": boxes[i][1] if i < len(boxes) else 0,
                    "x2": boxes[i][2] if i < len(boxes) else 0,
                    "y2": boxes[i][3] if i < len(boxes) else 0,
                },
                "center_point": mask["center"],
                "area": mask["area"],
                "confidence": confidences[i] if i < len(confidences) else 0.0,
                "is_target_part": any(part in phrases[i] if i < len(phrases) else "" for part in target_parts)
            }

            processed_result["segmented_regions"].append(region_info)

        # æ·»åŠ å¯è§†åŒ–ä¿¡æ¯
        processed_result["visualization"] = {
            "mask_overlay_generated": True,
            "colored_regions": True,
            "boundary_highlighted": True,
            "save_path": f"segmentation_result_{hash(str(target_parts)) % 10000}.png"
        }

        # æ·»åŠ è´¨é‡è¯„ä¼°
        processed_result["quality_assessment"] = self._assess_segmentation_quality(processed_result)

        return processed_result

    def _get_parameter_adjustments(self, issues: list) -> dict:
        """è·å–å‚æ•°è°ƒæ•´å»ºè®®"""
        adjustments = {}

        if "Low confidence scores" in issues:
            adjustments["segmentation_method"] = "å°è¯•ä¸åŒçš„åˆ†å‰²æ–¹æ³•"
        if "Some regions too small" in issues:
            adjustments["precision_level"] = "é™ä½ç²¾åº¦è¦æ±‚"
        if "No target parts detected" in issues:
            adjustments["text_prompt"] = "ä¼˜åŒ–æ–‡æœ¬æç¤ºæè¿°"

        return adjustments

    def _generate_planner_feedback(self, quality_assessment: dict, success: bool, retry_count: int) -> dict:
        """ç”Ÿæˆç»™ Planner çš„åé¦ˆ"""
        if success:
            return {
                "action": "proceed_to_next",
                "message": f"å›¾åƒåˆ†å‰²è´¨é‡è¾¾æ ‡ (å¾—åˆ†: {quality_assessment['overall_score']:.2f})",
                "retry_count": retry_count,
                "final_quality_score": quality_assessment['overall_score']
            }
        else:
            if retry_count >= self.max_retry_attempts:
                return {
                    "action": "max_retries_reached",
                    "message": f"å·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•° ({self.max_retry_attempts})ï¼Œè´¨é‡ä»ä¸è¾¾æ ‡",
                    "final_score": quality_assessment['overall_score'],
                    "final_issues": quality_assessment['issues'],
                    "recommendations": ["è€ƒè™‘æ›´æ¢è¾“å…¥å›¾åƒ", "è°ƒæ•´ä»»åŠ¡å‚æ•°", "ä½¿ç”¨äººå·¥å¹²é¢„"]
                }
            else:
                return {
                    "action": "quality_below_threshold",
                    "message": "åˆ†å‰²è´¨é‡ä½äºé˜ˆå€¼ï¼Œå»ºè®®ç»ˆæ­¢æˆ–è°ƒæ•´ç­–ç•¥",
                    "score": quality_assessment['overall_score'],
                    "threshold": self.min_quality_threshold,
                    "issues": quality_assessment['issues']
                }

    def _assess_segmentation_quality(self, result: dict) -> dict:
        """è¯„ä¼°åˆ†å‰²è´¨é‡"""
        regions = result.get("segmented_regions", [])

        if not regions:
            return {
                "overall_score": 0.0,
                "issues": ["No regions detected"],
                "average_confidence": 0.0,
                "average_size_score": 0.0,
                "recommendations": ["æ£€æŸ¥å›¾åƒè´¨é‡å’Œæ–‡æœ¬æç¤ºå‡†ç¡®æ€§", "å°è¯•ä¸åŒçš„åˆ†å‰²æ–¹æ³•"]
            }

        total_confidence = sum(region.get("confidence", 0) for region in regions)
        avg_confidence = total_confidence / len(regions)

        # æ£€æŸ¥åŒºåŸŸå¤§å°åˆç†æ€§
        size_scores = []
        for region in regions:
            area = region.get("area", 0)
            if 100 <= area <= 10000:  # åˆç†çš„åŒºåŸŸå¤§å°èŒƒå›´
                size_scores.append(1.0)
            elif area < 100:
                size_scores.append(0.5)  # åŒºåŸŸå¤ªå°
            else:
                size_scores.append(0.7)  # åŒºåŸŸè¾ƒå¤§ä½†å¯æ¥å—

        avg_size_score = sum(size_scores) / len(size_scores) if size_scores else 0.5

        # ç»¼åˆè¯„åˆ†
        overall_score = (avg_confidence * 0.6 + avg_size_score * 0.4)

        issues = []
        if avg_confidence < 0.7:
            issues.append("Low confidence scores")
        if any(region.get("area", 0) < 100 for region in regions):
            issues.append("Some regions too small")
        if len(regions) == 0:
            issues.append("No target parts detected")

        return {
            "overall_score": overall_score,
            "average_confidence": avg_confidence,
            "average_size_score": avg_size_score,
            "issues": issues,
            "recommendations": self._generate_recommendations(overall_score, issues)
        }


    def _generate_recommendations(self, score: float, issues: list) -> list:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []

        if score < 0.6:
            recommendations.append("Consider using different segmentation method")
        if "Low confidence scores" in issues:
            recommendations.append("Refine text prompt for better targeting")
        if "Some regions too small" in issues:
            recommendations.append("Adjust precision level or merge small regions")
        if "No target parts detected" in issues:
            recommendations.append("Check image quality and text prompt accuracy")

        return recommendations

class RigidMotionWorker(BaseWorker):
    def __init__(self):
        super(RigidMotionWorker, self).__init__("worker3","motionControl")
    async def execute(self,task)->WorkerResult:
        logger.info(f"Worker3æ‰§è¡Œç§»åŠ¨æ§åˆ¶ä»»åŠ¡:{task.description}")
        await asyncio.sleep(3)
        mock_data={
            "motion_frames":[f"frame_{i}.pcd" for i in range(10)],
            "motion_parameters":{
                "rotation_axis":[0,1,0],
                "rotation_angle":30,
                "translation":[0,0,0]
            },
            "frame_count":10
        }
        return WorkerResult(success=True,data=mock_data)

class VisualizationWorker(BaseWorker):
    """Worker4: å¯è§†åŒ–å·¥ä½œå™¨"""

    def __init__(self):
        super().__init__("worker4", "visualization")

    async def execute(self, task: Task) -> WorkerResult:
        """æ‰§è¡Œå¯è§†åŒ–ä»»åŠ¡"""
        logger.info(f"Worker4æ‰§è¡Œå¯è§†åŒ–ä»»åŠ¡: {task.description}")

        await asyncio.sleep(3)

        # TODO: å®é™…è°ƒç”¨pcdviewerå¹¶æˆªå±
        mock_result = {
            "screenshots": [f"screenshot_{i}.png" for i in range(10)],
            "video_path": "motion_animation.mp4",
            "evaluation_score": 0.85,
            "feedback": "åŠ¨ä½œæ•ˆæœè‰¯å¥½ï¼Œå»ºè®®è°ƒæ•´æ—‹è½¬è§’åº¦"
        }

        return WorkerResult(success=True, data=mock_result)

class QwenLLMClient:
    print(f"in qwen")
    def __init__(self,api_key="sk-f2dce495ff4c41509745ab5cfb6beba4",base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"):
        print(f"in qweninit")
        self.client=openai.OpenAI(api_key=api_key,base_url=base_url)
    async def call_llm(self,prompt:str,system_prompt:str="")->str:
        try:
            messages=[]
            if system_prompt:
                messages.append({"role":"system","content":system_prompt})
            messages.append({"role":"user","content":prompt})

            response=self.client.chat.completions.create(
                model="qwen1.5-72b-chat",
                messages=messages,
                temperature=0.7
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"LLMè°ƒç”¨å¤±è´¥{e}")
            return f"Error{e}"


class Planner:
    def __init__(self, llm_client: QwenLLMClient):
        self.llm_client = llm_client
        self.workers = {
            "image_segmentation": ImageSegmentationWorker(),
            "pointcloud_mapping": PointCloudMappingWorker(),
            "rigid_motion": RigidMotionWorker(),
            # "visualization": VisualizationWorker()
        }
        self.task_history = []
        self.knowledge_base = self._init_knowledge_base()

    async def analyze_instruction_with_thought_chain(self, instruction: str) -> List[ThoughtChain]:
        """ä½¿ç”¨æ€ç»´é“¾åˆ†æç”¨æˆ·æŒ‡ä»¤"""
        system_prompt = """
        ä½ æ˜¯ä¸€ä¸ªå¤šæ¨¡æ€ç‚¹äº‘æ§åˆ¶ç³»ç»Ÿçš„åˆ†æä¸“å®¶ã€‚è¯·ä½¿ç”¨æ€ç»´é“¾æ–¹æ³•æ·±åº¦åˆ†æç”¨æˆ·æŒ‡ä»¤ã€‚

        åˆ†æç»´åº¦ï¼š
        1. æŒ‡ä»¤ç†è§£ï¼šç†è§£ç”¨æˆ·æƒ³è¦å®ç°ä»€ä¹ˆ
        2. æŠ€æœ¯è·¯å¾„ï¼šç¡®å®šéœ€è¦å“ªäº›æŠ€æœ¯æ­¥éª¤
        3. èµ„æºéœ€æ±‚ï¼šåˆ†æéœ€è¦ä»€ä¹ˆèµ„æºå’Œèƒ½åŠ›
        4. æ‰§è¡Œç­–ç•¥ï¼šè§„åˆ’å¦‚ä½•æ‰§è¡Œ
        5. æ½œåœ¨é£é™©ï¼šè¯†åˆ«å¯èƒ½çš„é—®é¢˜

        è¿”å›JSONæ ¼å¼çš„æ€ç»´é“¾ï¼Œæ¯ä¸€æ­¥åŒ…å«æ€è€ƒè¿‡ç¨‹ã€æ¨ç†é€»è¾‘ã€å†³ç­–å’Œç½®ä¿¡åº¦ã€‚
        """

        prompt = f"""
        ç”¨æˆ·æŒ‡ä»¤: "{instruction}"

        è¯·è¿›è¡Œæ·±åº¦åˆ†æï¼Œè¿”å›JSONæ ¼å¼ï¼š
        {{
            "thought_chain": [
                {{
                    "step": 1,
                    "thought": "æŒ‡ä»¤ç†è§£",
                    "reasoning": "è¯¦ç»†çš„æ¨ç†è¿‡ç¨‹",
                    "decision": "åšå‡ºçš„å†³ç­–",
                    "confidence": 0.85
                }},
                {{
                    "step": 2,
                    "thought": "æŠ€æœ¯è·¯å¾„åˆ†æ",
                    "reasoning": "æŠ€æœ¯å®ç°çš„æ¨ç†",
                    "decision": "é€‰æ‹©çš„æŠ€æœ¯è·¯å¾„",
                    "confidence": 0.90
                }},
                {{
                    "step": 3,
                    "thought": "èµ„æºå’Œèƒ½åŠ›è¯„ä¼°",
                    "reasoning": "èµ„æºéœ€æ±‚åˆ†æ",
                    "decision": "èµ„æºåˆ†é…ç­–ç•¥",
                    "confidence": 0.80
                }},
                {{
                    "step": 4,
                    "thought": "æ‰§è¡Œç­–ç•¥åˆ¶å®š",
                    "reasoning": "æ‰§è¡Œæ–¹æ¡ˆæ¨ç†",
                    "decision": "å…·ä½“æ‰§è¡Œç­–ç•¥",
                    "confidence": 0.88
                }},
                {{
                    "step": 5,
                    "thought": "é£é™©è¯†åˆ«",
                    "reasoning": "æ½œåœ¨é—®é¢˜åˆ†æ",
                    "decision": "é£é™©åº”å¯¹æªæ–½",
                    "confidence": 0.75
                }}
            ]
        }}
        """

        try:
            response = await self.llm_client.call_llm(prompt, system_prompt)
            logger.info(f"æ€ç»´é“¾åˆ†æç»“æœ: {response}")

            parsed_response = json.loads(response)
            thought_chains = []

            for chain_data in parsed_response.get("thought_chain", []):
                thought_chain = ThoughtChain(
                    step=chain_data["step"],
                    thought=chain_data["thought"],
                    reasoning=chain_data["reasoning"],
                    decision=chain_data["decision"],
                    confidence=chain_data["confidence"]
                )
                thought_chains.append(thought_chain)

            return thought_chains

        except (json.JSONDecodeError, KeyError) as e:
            logger.error(f"è§£ææ€ç»´é“¾åˆ†æç»“æœå¤±è´¥: {e}")
            return self._get_fallback_thought_chain(instruction)
    def _init_knowledge_base(self) -> Dict[str, Any]:
        """åˆå§‹åŒ–é¢†åŸŸçŸ¥è¯†åº“"""
        return {
            "motion_types": {
                "æŒ¥èˆ": {"parts": ["æ‰‹", "è‡‚"], "motion": "rotation", "axis": [0, 1, 0]},
                "æ‘†åŠ¨": {"parts": ["å°¾å·´", "å¤´"], "motion": "oscillation", "axis": [0, 0, 1]},
                "è½¬åŠ¨": {"parts": ["å¤´", "èº«ä½“"], "motion": "rotation", "axis": [0, 1, 0]},
                "è·³è·ƒ": {"parts": ["è…¿", "èº«ä½“"], "motion": "translation", "axis": [0, 1, 0]},
                "ç‚¹å¤´": {"parts": ["å¤´"], "motion": "rotation", "axis": [1, 0, 0]},
                "æ‘‡å¤´": {"parts": ["å¤´"], "motion": "rotation", "axis": [0, 1, 0]}
            },
            "animals": {
                "æ¾é¼ ": {"typical_parts": ["å¤´", "èº«ä½“", "æ‰‹", "è…¿", "å°¾å·´"], "size": "small"},
                "çŒ«": {"typical_parts": ["å¤´", "èº«ä½“", "çˆªå­", "è…¿", "å°¾å·´"], "size": "medium"},
                "ç‹—": {"typical_parts": ["å¤´", "èº«ä½“", "è…¿", "å°¾å·´"], "size": "medium"},
                "äºº": {"typical_parts": ["å¤´", "èº«ä½“", "æ‰‹", "è‡‚", "è…¿"], "size": "large"}
            },
            "segmentation_strategies": {
                "small_parts": "lang_sam",  # å°éƒ¨ä»¶ç”¨Lang-SAM
                "large_objects": "dino",  # å¤§ç‰©ä½“ç”¨DINO
                "precise_parts": "lang_sam"  # ç²¾ç¡®éƒ¨ä»¶ç”¨Lang-SAM
            }
        }

    async def plan_tasks(self, user_instruction: str) -> List[Task]:
        system_prompt = """
            ä½ æ˜¯ä¸€ä¸ªå¤šæ¨¡æ€ç‚¹äº‘æ§åˆ¶ç³»ç»Ÿçš„ä»»åŠ¡è§„åˆ’å™¨ã€‚æ ¹æ®ç”¨æˆ·æŒ‡ä»¤ï¼Œä½ éœ€è¦è§„åˆ’å‡ºåˆç†çš„ä»»åŠ¡æ‰§è¡Œåºåˆ—ã€‚

            å¯ç”¨çš„Workerç±»å‹ï¼š
            1. image_segmentation: å›¾åƒåˆ†å‰²ï¼Œè¯†åˆ«ç›®æ ‡åŒºåŸŸ
            2. pointcloud_mapping: å»ºç«‹2Då›¾åƒä¸3Dç‚¹äº‘çš„æ˜ å°„å…³ç³»
            3. rigid_motion: ä¸ºç‚¹äº‘æ·»åŠ åˆšæ€§è¿åŠ¨æ§åˆ¶
            4. visualization: å¯è§†åŒ–ç‚¹äº‘åŠ¨ç”»å¹¶è¯„ä¼°æ•ˆæœ

            è¯·è¿”å›JSONæ ¼å¼çš„ä»»åŠ¡è§„åˆ’ç»“æœã€‚        
        """
        prompt = f"""
        ç”¨æˆ·æŒ‡ä»¤: {user_instruction}
        è¯·è§„åˆ’æ‰§è¡Œä»»åŠ¡åºåˆ—ï¼Œè¿”å›JSONæ ¼å¼ï¼š
        {{
            "tasks": [
                {{
                    "worker_type": "workerç±»å‹",
                    "description": "ä»»åŠ¡æè¿°",
                    "input_requirements": {{"key": "value"}}
                }}
            ],
            "execution_order": ["task1", "task2", "task3", "task4"],
            "dependencies": {{"task2": ["task1"], "task3": ["task2"]}}
        }}        
        """
        response = await self.llm_client.call_llm(prompt, system_prompt)
        logger.into(f"LLMè§„åˆ’ç»“æœ:{response}")
        try:
            plan_data = json.loads(response)
            tasks = []
            for i, task_info in enumerate(plan_data.get("tasks", [])):
                task = Task(
                    task_id=f"task{i + 1}",
                    worker_type=task_info["worker_type"],
                    description=task_info["description"],
                    input_data=task_info.get("input_requirements", {})
                )
                tasks.append(task)
            return tasks
        except json.JSONDecodeError:
            logger.error("LLMè¿”å›çš„JSONæ ¼å¼é”™è¯¯")
            return self._get_default_tasks(user_instruction)

    def _get_fallback_thought_chain(self, instruction: str) -> List[ThoughtChain]:
        """è·å–å¤‡ç”¨æ€ç»´é“¾"""
        return [
            ThoughtChain(1, "æŒ‡ä»¤ç†è§£", f"åˆ†ææŒ‡ä»¤: {instruction}", "éœ€è¦å®Œæ•´çš„å¤šæ¨¡æ€å¤„ç†æµç¨‹", 0.8),
            ThoughtChain(2, "æŠ€æœ¯è·¯å¾„åˆ†æ", "éœ€è¦å›¾åƒåˆ†å‰²->ç‚¹äº‘æ˜ å°„->è¿åŠ¨æ§åˆ¶->å¯è§†åŒ–", "æŒ‰é¡ºåºæ‰§è¡Œå››ä¸ªæ ¸å¿ƒæ­¥éª¤", 0.9),
            ThoughtChain(3, "èµ„æºè¯„ä¼°", "éœ€è¦å›¾åƒå¤„ç†ã€3Då»ºæ¨¡ã€åŠ¨ç”»ç”Ÿæˆèƒ½åŠ›", "ä½¿ç”¨ç°æœ‰workerèµ„æº", 0.85),
            ThoughtChain(4, "æ‰§è¡Œç­–ç•¥", "é‡‡ç”¨ä¸²è¡Œæ‰§è¡Œï¼Œæ¯æ­¥ä¾èµ–å‰ä¸€æ­¥ç»“æœ", "é¡ºåºæ‰§è¡Œæ‰€æœ‰worker", 0.88),
            ThoughtChain(5, "é£é™©è¯†åˆ«", "å¯èƒ½å­˜åœ¨åˆ†å‰²ä¸å‡†ç¡®ã€æ˜ å°„é”™è¯¯ç­‰é—®é¢˜", "éœ€è¦é€‚å½“çš„å®¹é”™æœºåˆ¶", 0.75)
        ]
    #planneræ ¸å¿ƒä»»åŠ¡ï¼Œè°ƒç”¨llmè§£ææŒ‡ä»¤ç”Ÿæˆåˆ¶å®šå¥½çš„æ–¹æ¡ˆ
    async def plan_tasks_with_reasoning(self, instruction: str) -> TaskPlan:
        """åŸºäºæ€ç»´é“¾è¿›è¡Œè¯¦ç»†ä»»åŠ¡è§„åˆ’ - ä¸»å…¥å£æ–¹æ³•"""
        logger.info(f"å¼€å§‹è§„åˆ’ä»»åŠ¡ï¼Œç”¨æˆ·æŒ‡ä»¤: {instruction}")

        # 1. å…ˆè¿›è¡Œæ€ç»´é“¾åˆ†æ
        thought_chain = await self.analyze_instruction_with_thought_chain(instruction)
        logger.info(f"æ€ç»´é“¾åˆ†æå®Œæˆï¼Œå…±{len(thought_chain)}ä¸ªæ­¥éª¤")

        # 2. åŸºäºæ€ç»´é“¾ç»“æœè¿›è¡Œç²¾ç»†åŒ–ä»»åŠ¡è§„åˆ’
        detailed_plan = await self._create_detailed_task_plan(instruction, thought_chain)
        logger.info(f"ä»»åŠ¡è§„åˆ’å®Œæˆï¼Œå…±{len(detailed_plan.tasks)}ä¸ªä»»åŠ¡")

        return detailed_plan

    async def _create_detailed_task_plan(self, instruction: str, thought_chain: List[ThoughtChain]) -> TaskPlan:
        """åˆ›å»ºè¯¦ç»†çš„ä»»åŠ¡è§„åˆ’"""
        logger.info("å¼€å§‹åˆ›å»ºè¯¦ç»†ä»»åŠ¡è§„åˆ’")

        # 1. æ™ºèƒ½è§£ææŒ‡ä»¤å†…å®¹
        parsed_info = await self._parse_instruction_semantics(instruction)
        logger.info(f"æŒ‡ä»¤è¯­ä¹‰è§£æå®Œæˆ: {parsed_info}")

        # 2. æ ¹æ®è§£æç»“æœå’Œæ€ç»´é“¾ç”Ÿæˆé€‚åº”æ€§ä»»åŠ¡
        tasks = await self._generate_adaptive_tasks(instruction, parsed_info, thought_chain)
        logger.info(f"ç”Ÿæˆäº†{len(tasks)}ä¸ªè‡ªé€‚åº”ä»»åŠ¡")

        return TaskPlan(
            tasks=tasks,
            thought_chain=thought_chain
        )

    async def _parse_instruction_semantics(self, instruction: str) -> Dict[str, Any]:
        """æ·±åº¦è§£ææŒ‡ä»¤è¯­ä¹‰"""
        system_prompt = """
        ä½ æ˜¯è¯­ä¹‰è§£æä¸“å®¶ã€‚è¯·æ·±åº¦åˆ†æç”¨æˆ·æŒ‡ä»¤ï¼Œæå–å…³é”®è¯­ä¹‰ä¿¡æ¯ã€‚

        éœ€è¦æå–çš„ä¿¡æ¯ï¼š
        1. åŠ¨ä½œä¸»ä½“ï¼ˆä»€ä¹ˆå¯¹è±¡ï¼‰
        2. åŠ¨ä½œç±»å‹ï¼ˆåšä»€ä¹ˆåŠ¨ä½œï¼‰  
        3. ç›®æ ‡éƒ¨ä½ï¼ˆå“ªä¸ªéƒ¨åˆ†ï¼‰
        4. åŠ¨ä½œç‰¹å¾ï¼ˆå¦‚ä½•åšï¼‰
        5. æŠ€æœ¯éœ€æ±‚ï¼ˆéœ€è¦ä»€ä¹ˆæŠ€æœ¯æ”¯æŒï¼‰
        """

        prompt = f"""
        æŒ‡ä»¤: "{instruction}"

        è¯·æå–è¯­ä¹‰ä¿¡æ¯ï¼Œè¿”å›JSONï¼š
        {{
            "subject": "åŠ¨ä½œä¸»ä½“",
            "action": "åŠ¨ä½œç±»å‹", 
            "target_parts": ["ç›®æ ‡éƒ¨ä½åˆ—è¡¨"],
            "motion_characteristics": {{
                "type": "è¿åŠ¨ç±»å‹",
                "amplitude": "è¿åŠ¨å¹…åº¦",
                "frequency": "è¿åŠ¨é¢‘ç‡",
                "direction": "è¿åŠ¨æ–¹å‘"
            }},
            "technical_requirements": {{
                "segmentation_precision": "åˆ†å‰²ç²¾åº¦è¦æ±‚",
                "mapping_complexity": "æ˜ å°„å¤æ‚åº¦",
                "motion_complexity": "è¿åŠ¨å¤æ‚åº¦"
            }},
            "success_criteria": ["æˆåŠŸæ ‡å‡†åˆ—è¡¨"]
        }}
        """

        response = await self.llm_client.call_llm(prompt, system_prompt)

        try:
            return json.loads(response)
        except json.JSONDecodeError:
            # ä½¿ç”¨çŸ¥è¯†åº“è¿›è¡Œå¤‡ç”¨è§£æ
            return self._fallback_semantic_parse(instruction)

    def _fallback_semantic_parse(self, instruction: str) -> Dict[str, Any]:
        """åŸºäºçŸ¥è¯†åº“çš„å¤‡ç”¨è¯­ä¹‰è§£æ"""
        parsed_info = {
            "subject": "æœªçŸ¥å¯¹è±¡",
            "action": "æœªçŸ¥åŠ¨ä½œ",
            "target_parts": ["å…¨èº«"],
            "motion_characteristics": {
                "type": "unknown",
                "amplitude": "medium",
                "frequency": "low",
                "direction": "multi"
            },
            "technical_requirements": {
                "segmentation_precision": "high",
                "mapping_complexity": "medium",
                "motion_complexity": "medium"
            },
            "success_criteria": ["åŠ¨ä½œè‡ªç„¶", "éƒ¨ä½å‡†ç¡®", "æ•ˆæœæµç•…"]
        }

        # åŸºäºçŸ¥è¯†åº“åŒ¹é…
        for animal, info in self.knowledge_base["animals"].items():
            if animal in instruction:
                parsed_info["subject"] = animal
                parsed_info["target_parts"] = info["typical_parts"]
                break

        for motion, info in self.knowledge_base["motion_types"].items():
            if motion in instruction:
                parsed_info["action"] = motion
                parsed_info["target_parts"] = info["parts"]
                parsed_info["motion_characteristics"]["type"] = info["motion"]
                break

        return parsed_info

    async def _generate_adaptive_tasks(self, instruction: str, parsed_info: Dict, thought_chain: List[ThoughtChain]) -> \
            List[Task]:
        """ç”Ÿæˆè‡ªé€‚åº”ä»»åŠ¡åºåˆ—"""
        tasks = []

        # Task 1: æ™ºèƒ½å›¾åƒåˆ†å‰²
        segmentation_strategy = self._choose_segmentation_strategy(parsed_info)
        task1 = Task(
            task_id="task_segmentation",
            worker_type="image_segmentation",
            description=f"ä½¿ç”¨{segmentation_strategy}åˆ†å‰²{parsed_info.get('subject', 'ç›®æ ‡å¯¹è±¡')}çš„{','.join(parsed_info.get('target_parts', ['ç›®æ ‡éƒ¨ä½']))}",
            input_data={
                "instruction": instruction,
                "target_subject": parsed_info.get("subject"),
                "target_parts": parsed_info.get("target_parts", []),
                "segmentation_method": segmentation_strategy,
                "precision_level": parsed_info.get("technical_requirements", {}).get("segmentation_precision", "high")
            }
        )
        tasks.append(task1)

        # Task 2: è‡ªé€‚åº”ç‚¹äº‘æ˜ å°„
        mapping_complexity = parsed_info.get("technical_requirements", {}).get("mapping_complexity", "medium")
        task2 = Task(
            task_id="task_mapping",
            worker_type="pointcloud_mapping",
            description=f"å»ºç«‹{parsed_info.get('subject')}çš„å¤šåˆ†è¾¨ç‡ç‚¹äº‘æ˜ å°„ï¼Œå¤æ‚åº¦:{mapping_complexity}",
            input_data={
                "instruction": instruction,
                "target_parts": parsed_info.get("target_parts", []),
                "mapping_precision": "high" if mapping_complexity == "high" else "medium",
                "resolution_strategy": "multi_scale"
            }
        )
        tasks.append(task2)

        # Task 3: ç²¾å‡†è¿åŠ¨æ§åˆ¶
        motion_params = self._calculate_motion_parameters(parsed_info)
        task3 = Task(
            task_id="task_motion",
            worker_type="rigid_motion",
            description=f"ä¸º{','.join(parsed_info.get('target_parts', []))}æ·»åŠ {parsed_info.get('action')}è¿åŠ¨æ§åˆ¶",
            input_data={
                "instruction": instruction,
                "motion_type": parsed_info.get("motion_characteristics", {}).get("type", "rotation"),
                "motion_parameters": motion_params,
                "target_parts": parsed_info.get("target_parts", []),
                "animation_frames": self._calculate_frame_count(parsed_info)
            }
        )
        tasks.append(task3)

        # Task 4: æ™ºèƒ½å¯è§†åŒ–è¯„ä¼°
        task4 = Task(
            task_id="task_visualization",
            worker_type="visualization",
            description=f"å¯è§†åŒ–{parsed_info.get('action')}åŠ¨ç”»å¹¶æ™ºèƒ½è¯„ä¼°æ•ˆæœ",
            input_data={
                "instruction": instruction,
                "success_criteria": parsed_info.get("success_criteria", []),
                "evaluation_focus": parsed_info.get("target_parts", []),
                "quality_threshold": 0.8
            }
        )
        tasks.append(task4)

        return tasks

    def _choose_segmentation_strategy(self, parsed_info: Dict[str, Any]) -> str:
        """é€‰æ‹©åˆ†å‰²ç­–ç•¥"""
        subject = parsed_info.get("subject", "")
        target_parts = parsed_info.get("target_parts", [])

        # åŸºäºä¸»ä½“å¤§å°é€‰æ‹©ç­–ç•¥
        if subject in self.knowledge_base["animals"]:
            size = self.knowledge_base["animals"][subject]["size"]
            if size == "small":
                return "lang_sam"  # å°ç‰©ä½“ç”¨ç²¾ç¡®åˆ†å‰²
            elif size == "large":
                return "dino"  # å¤§ç‰©ä½“ç”¨DINO

        # åŸºäºéƒ¨ä½ç²¾åº¦è¦æ±‚
        if any(part in ["æ‰‹", "çœ¼", "é¼»"] for part in target_parts):
            return "lang_sam"  # ç²¾ç»†éƒ¨ä½ç”¨Lang-SAM

        return "dino"  # é»˜è®¤ä½¿ç”¨DINO

    def _get_default_tasks(self, instruction: str) -> List[Task]:
        return [
            Task("task1", "image_segmentation", "å›¾åƒåˆ†å‰²ä»»åŠ¡", {"instruction": instruction}),
            Task("task2", "pointcloud_mapping", "ç‚¹äº‘æ˜ å°„ä»»åŠ¡", {"instruction": instruction}),
            Task("task3", "rigid_motion", "åˆšæ€§è¿åŠ¨ä»»åŠ¡", {"instruction": instruction}),
            Task("task4", "visualization", "å¯è§†åŒ–ä»»åŠ¡", {"instruction": instruction})
        ]
    async def execute_task_plan(self,task_plan:TaskPlan)->Optional:
        return 'success'
    async def evaluate_and_improve(self, results: Dict[str, Any]) -> bool:
        # viz_result = results.get("task4", {})
        # if viz_result.get("status") == "success":
        #     evaluation_score = viz_result.get("data", {}).get("evaluation_score", 0)
        #     feedback = viz_result.get("data", {}).get("feedback", "")
        #     logger.info(f"è¯„ä¼°åˆ†æ•°: {evaluation_score}, åé¦ˆ: {feedback}")
        #
        #     if evaluation_score < 0.8:
        #         logger.info("è¯„ä¼°åˆ†æ•°è¾ƒä½")
        #         return True
        return True

class AgentSystem:
    def __init__(self):
        print(f"before llm_client")
        self.llm_client=QwenLLMClient()
        print(f"in llm_client")
        self.planner=Planner(self.llm_client)
        self.max_iterations=3
    async def process_user_instruction(self,instruction:str)->str:
        logger.info(f"æ¥æ”¶ç”¨æˆ·æŒ‡ä»¤:{instruction}")
        iteration=0
        while iteration<self.max_iterations:
            iteration+=1
            logger.info(f"å¼€å§‹ç¬¬{iteration}æ¬¡è¿­ä»£æ‰§è¡Œ")
            try:
                task_plan=await self.planner.plan_tasks_with_reasoning(instruction)
                logger.info(f"ä»»åŠ¡è§„åˆ’å®Œæˆï¼Œç”Ÿæˆ{len(task_plan.tasks)}ä¸ªä»»åŠ¡")
                self._log_thought_chain(task_plan.thought_chain)

                results=await self.planner.execute_task_plan(task_plan)
                #need_improvement=await self.planner.evaluate_and_improve(results)
                # 3. ç®€åŒ–ç‰ˆè¯„ä¼°ï¼ˆæš‚æ—¶ä¸è€ƒè™‘åæ€æœºåˆ¶ï¼‰
                success = self._evaluate_results(results, task_plan)

                if success:
                    logger.info("ä»»åŠ¡æ‰§è¡ŒæˆåŠŸï¼Œæ•ˆæœæ»¡æ„")
                    return self._generate_completion_message(results, task_plan)
                else:
                    logger.info(f"ç¬¬{iteration}æ¬¡è¿­ä»£ç»“æœä¸æ»¡æ„ï¼Œå‡†å¤‡é‡æ–°æ‰§è¡Œ")
                    if iteration < self.max_iterations:
                        # ä¸ºä¸‹æ¬¡è¿­ä»£å‡†å¤‡ä¼˜åŒ–åçš„æŒ‡ä»¤
                        instruction = self._optimize_instruction_for_retry(instruction, results, task_plan)
                        continue
                    else:
                        logger.warning("è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œè¿”å›å½“å‰ç»“æœ")
                        return self._generate_completion_message(results, task_plan, is_final=True)
            except Exception as e:
                logger.error(f"ç¬¬{iteration}æ¬¡è¿­ä»£æ‰§è¡Œå‡ºé”™: {str(e)}")
                if iteration >= self.max_iterations:
                    return f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°ã€‚é”™è¯¯ä¿¡æ¯: {str(e)}"
                continue

        return "ä»»åŠ¡æ‰§è¡Œå®Œæˆ"

    def _optimize_instruction_for_retry(self, original_instruction: str, results: Dict[str, Any],
                                        task_plan: TaskPlan) -> str:
        """
        ä¸ºé‡è¯•ä¼˜åŒ–æŒ‡ä»¤
        æ ¹æ®å¤±è´¥çš„ä»»åŠ¡å’Œç»“æœï¼Œå¯¹æŒ‡ä»¤è¿›è¡Œå¾®è°ƒ
        """
        try:
            # åˆ†æå¤±è´¥çš„ä»»åŠ¡
            failed_tasks = [task for task in task_plan.tasks if task.status == TaskStatus.FAILED]

            if failed_tasks:
                # æ ¹æ®å¤±è´¥ä»»åŠ¡ç±»å‹è°ƒæ•´æŒ‡ä»¤
                failed_types = [task.worker_type for task in failed_tasks]

                if "image_segmentation" in failed_types:
                    # å¦‚æœå›¾åƒåˆ†å‰²å¤±è´¥ï¼Œå¯èƒ½éœ€è¦æ›´æ˜ç¡®çš„æè¿°
                    return f"{original_instruction}ï¼ˆè¯·æ›´ç²¾ç¡®åœ°åˆ†å‰²ç›®æ ‡åŒºåŸŸï¼‰"
                elif "pointcloud_mapping" in failed_types:
                    # å¦‚æœç‚¹äº‘æ˜ å°„å¤±è´¥ï¼Œå¯èƒ½éœ€è¦é™ä½å¤æ‚åº¦
                    return f"{original_instruction}ï¼ˆä½¿ç”¨æ›´ç®€å•çš„æ˜ å°„ç­–ç•¥ï¼‰"
                elif "rigid_motion" in failed_types:
                    # å¦‚æœè¿åŠ¨æ§åˆ¶å¤±è´¥ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´è¿åŠ¨å‚æ•°
                    return f"{original_instruction}ï¼ˆä½¿ç”¨æ›´å¹³æ»‘çš„è¿åŠ¨æ•ˆæœï¼‰"
                elif "visualization" in failed_types:
                    # å¦‚æœå¯è§†åŒ–å¤±è´¥ï¼Œå¯èƒ½éœ€è¦ç®€åŒ–æ¸²æŸ“
                    return f"{original_instruction}ï¼ˆä½¿ç”¨åŸºç¡€å¯è§†åŒ–æ¨¡å¼ï¼‰"

            # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„å¤±è´¥æ¨¡å¼ï¼Œè¿”å›åŸæŒ‡ä»¤
            return original_instruction

        except Exception as e:
            logger.error(f"æŒ‡ä»¤ä¼˜åŒ–å‡ºé”™: {str(e)}")
            return original_instruction

    def _generate_completion_message(self, results: Dict[str, Any], task_plan: TaskPlan,
                                     is_final: bool = False) -> str:
        """
        ç”Ÿæˆå®Œæˆæ¶ˆæ¯
        """
        try:
            message_parts = []

            if is_final:
                message_parts.append("ä»»åŠ¡æ‰§è¡Œå·²å®Œæˆï¼ˆå·²è¾¾æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼‰")
            else:
                message_parts.append("ä»»åŠ¡æ‰§è¡ŒæˆåŠŸå®Œæˆ")

            # æ·»åŠ æ‰§è¡Œæ‘˜è¦
            completed_tasks = [task for task in task_plan.tasks if task.status == TaskStatus.COMPLETED]
            failed_tasks = [task for task in task_plan.tasks if task.status == TaskStatus.FAILED]

            message_parts.append(f"æˆåŠŸæ‰§è¡Œäº†{len(completed_tasks)}ä¸ªä»»åŠ¡")
            if failed_tasks:
                message_parts.append(f"æœ‰{len(failed_tasks)}ä¸ªä»»åŠ¡æ‰§è¡Œå¤±è´¥")

            # æ·»åŠ ä¸»è¦ç»“æœä¿¡æ¯
            if "task_visualization" in results:
                viz_result = results["task_visualization"]
                if isinstance(viz_result, dict):
                    status = viz_result.get("status", "unknown")
                    message_parts.append(f"å¯è§†åŒ–ç»“æœ: {status}")

            # æ·»åŠ æ€ç»´é“¾ç½®ä¿¡åº¦æ‘˜è¦
            if task_plan.thought_chain:
                avg_confidence = sum(chain.confidence for chain in task_plan.thought_chain) / len(
                    task_plan.thought_chain)
                message_parts.append(f"å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.2f}")

            return "\n".join(message_parts)

        except Exception as e:
            logger.error(f"ç”Ÿæˆå®Œæˆæ¶ˆæ¯å‡ºé”™: {str(e)}")
            return "ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼Œä½†ç”Ÿæˆæ‘˜è¦æ—¶å‡ºç°é”™è¯¯"



def show_help_examples():
    """æ˜¾ç¤ºå¸®åŠ©å’Œç¤ºä¾‹"""
    print("\n" + "=" * 60)
    print("ğŸ“š æŒ‡ä»¤ç¤ºä¾‹å’Œå¸®åŠ©")
    print("=" * 60)

    examples = [
        {
            "category": "ğŸ¿ï¸ åŠ¨ç‰©åŠ¨ä½œæ§åˆ¶",
            "examples": [
                "è®©æ¾é¼ æŒ¥èˆæ‰‹è‡‚",
                "è®©çŒ«æ‘†åŠ¨å°¾å·´",
                "è®©ç‹—æ‘‡å¤´",
                "è®©äººç‚¹å¤´"
            ]
        },
        {
            "category": "ğŸ­ å¤æ‚åŠ¨ä½œç»„åˆ",
            "examples": [
                "è®©æ¾é¼ å…ˆç‚¹å¤´ç„¶åæŒ¥èˆæ‰‹è‡‚",
                "è®©çŒ«ä¸€è¾¹æ‘†å°¾å·´ä¸€è¾¹è½¬å¤´",
                "è®©äººåšè·³è·ƒåŠ¨ä½œ"
            ]
        },
        {
            "category": "ğŸ¨ ç‰¹å®šéƒ¨ä½æ§åˆ¶",
            "examples": [
                "åªè®©æ¾é¼ çš„å¤´éƒ¨è½¬åŠ¨",
                "è®©çŒ«çš„å‰çˆªåšæŒ¥èˆåŠ¨ä½œ",
                "æ§åˆ¶äººçš„æ‰‹è‡‚åšæ‘†åŠ¨"
            ]
        }
    ]

    for category_info in examples:
        print(f"\n{category_info['category']}:")
        for i, example in enumerate(category_info['examples'], 1):
            print(f"  {i}. {example}")

    print("\n" + "=" * 60)
    print("ğŸ’¡ æç¤º:")
    print("â€¢ ä½¿ç”¨è‡ªç„¶è¯­è¨€æè¿°å³å¯ï¼Œç³»ç»Ÿä¼šæ™ºèƒ½è§£æ")
    print("â€¢ æ”¯æŒä¸­æ–‡æŒ‡ä»¤ï¼Œæè¿°è¶Šè¯¦ç»†æ•ˆæœè¶Šå¥½")
    print("â€¢ ç³»ç»Ÿä¼šè‡ªåŠ¨é€‰æ‹©æœ€é€‚åˆçš„å¤„ç†ç­–ç•¥")
    print("=" * 60)
async def main():
    """ä¸»å‡½æ•° - å¤šæ¨¡æ€ç‚¹äº‘æ§åˆ¶Agentç³»ç»Ÿ"""
    print("=" * 70)
    print("ğŸ¯ å¤šæ¨¡æ€ç‚¹äº‘æ§åˆ¶Agentç³»ç»Ÿ v2.0")
    print("=" * 70)
    print("ç³»ç»Ÿç‰¹æ€§:")
    print("â€¢ æ™ºèƒ½æ€ç»´é“¾åˆ†æ")
    print("â€¢ è‡ªé€‚åº”ä»»åŠ¡è§„åˆ’")
    print("â€¢ å¤šæ¨¡æ€å¤„ç†æµç¨‹")
    print("â€¢ å®æ—¶å¯è§†åŒ–åé¦ˆ")
    print("=" * 70)

    # åˆå§‹åŒ–ç³»ç»Ÿ
    try:
        print("\nğŸ”§ æ­£åœ¨åˆå§‹åŒ–ç³»ç»Ÿ...")
        # æ³¨æ„ï¼šè¯·æ›¿æ¢ä¸ºå®é™…çš„APIå¯†é’¥å’Œåœ°å€
        system = AgentSystem()
        print("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

        # æ˜¾ç¤ºä½¿ç”¨æç¤º
        print("\nğŸ“– ä½¿ç”¨æŒ‡å—:")
        print("â€¢ æ”¯æŒè‡ªç„¶è¯­è¨€æè¿°åŠ¨ä½œæŒ‡ä»¤")
        print("â€¢ ä¾‹å¦‚: 'è®©æ¾é¼ æŒ¥èˆæ‰‹è‡‚'ã€'è®©çŒ«æ‘†åŠ¨å°¾å·´'")
        print("â€¢ è¾“å…¥ 'help' æŸ¥çœ‹æ›´å¤šç¤ºä¾‹")
        print("â€¢ è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡ºç³»ç»Ÿ")

    except Exception as e:
        import traceback
        traceback.print_exc()
        print(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
        logger.error(f"ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
        return

    session_count = 0

    while True:
        try:
            # è·å–ç”¨æˆ·è¾“å…¥
            instruction = input(f"\n[ä¼šè¯ {session_count + 1}] è¯·è¾“å…¥æ§åˆ¶æŒ‡ä»¤: ").strip()

            # å¤„ç†ç‰¹æ®Šå‘½ä»¤
            if instruction.lower() in ['quit', 'exit', 'q']:
                print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨å¤šæ¨¡æ€ç‚¹äº‘æ§åˆ¶ç³»ç»Ÿï¼Œå†è§ï¼")
                break

            if instruction.lower() == 'help':
                show_help_examples()
                continue

            if not instruction:
                print("âš ï¸  è¯·è¾“å…¥æœ‰æ•ˆçš„æŒ‡ä»¤")
                continue

            # å¤„ç†ç”¨æˆ·æŒ‡ä»¤
            session_count += 1
            print(f"\nğŸš€ æ­£åœ¨å¤„ç†æ‚¨çš„æŒ‡ä»¤: '{instruction}'")
            print("ğŸ“Š æ‰§è¡Œæµç¨‹: æ€ç»´é“¾åˆ†æ â†’ ä»»åŠ¡è§„åˆ’ â†’ æ‰§è¡Œå¤„ç† â†’ ç»“æœè¯„ä¼°")
            print("-" * 60)

            start_time = asyncio.get_event_loop().time()

            # è°ƒç”¨æ›´æ–°åçš„å¤„ç†æ–¹æ³•
            completion_message = await system.process_user_instruction(instruction)

            end_time = asyncio.get_event_loop().time()
            execution_time = end_time - start_time

            # æ˜¾ç¤ºç»“æœ
            print("\n" + "=" * 60)
            print("ğŸ“‹ ä»»åŠ¡å®ŒæˆæŠ¥å‘Š")
            print("=" * 60)
            print(completion_message)
            print("-" * 60)
            print(f"â±ï¸  æ‰§è¡Œè€—æ—¶: {execution_time:.2f}ç§’")
            print(f"ğŸ”¢ ä¼šè¯ç¼–å·: {session_count}")
            print("=" * 60)

        except KeyboardInterrupt:
            print("\n\nâš ï¸  ç³»ç»Ÿè¢«ç”¨æˆ·ä¸­æ–­")
            user_choice = input("æ˜¯å¦è¦é€€å‡ºç³»ç»Ÿ? (y/n): ").strip().lower()
            if user_choice in ['y', 'yes']:
                print("ğŸ‘‹ ç³»ç»Ÿé€€å‡º")
                break
            else:
                print("ç»§ç»­è¿è¡Œ...")
                continue

        except Exception as e:
            session_count += 1  # å³ä½¿å‡ºé”™ä¹Ÿè®¡å…¥ä¼šè¯
            print(f"\nâŒ ç³»ç»Ÿæ‰§è¡Œé”™è¯¯: {e}")
            print("ğŸ’¡ å»ºè®®:")
            print("  â€¢ æ£€æŸ¥æŒ‡ä»¤æ ¼å¼æ˜¯å¦æ­£ç¡®")
            print("  â€¢ ç¡®è®¤ç½‘ç»œè¿æ¥æ­£å¸¸")
            print("  â€¢ å°è¯•é‡æ–°è¾“å…¥æŒ‡ä»¤")
            logger.error(f"ä¼šè¯{session_count}æ‰§è¡Œé”™è¯¯: {e}")

            # è¯¢é—®æ˜¯å¦ç»§ç»­
            continue_choice = input("\næ˜¯å¦ç»§ç»­ä½¿ç”¨ç³»ç»Ÿ? (y/n): ").strip().lower()
            if continue_choice not in ['y', 'yes', '']:
                print("ğŸ‘‹ ç³»ç»Ÿé€€å‡º")
                break


if __name__ == "__main__":
    asyncio.run(main())